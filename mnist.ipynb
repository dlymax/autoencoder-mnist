{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, float_, zeros\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data and visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(dataset = \"training\", digits=np.arange(10), path = \"data\"):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "        \n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows * cols), dtype=float_)\n",
    "    labels = zeros((N, 10), dtype=float_)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows * cols))\n",
    "        labels[i,lbl[ind[i]]] = 1.0\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "X_train, Y_train = load_mnist(dataset=\"training\")\n",
    "X_test, Y_test = load_mnist(dataset=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e009c1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline \n",
    "import random\n",
    "\n",
    "rand = np.random.randint(len(X_train))\n",
    "plt.imshow(X_train[rand].reshape((28,28)), cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_width = 28\n",
    "n_visible = np.power(mnist_width, 2)\n",
    "n_hidden = 500\n",
    "corruption_level = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, mask, W, b, W_prime, b_prime):\n",
    "    # X filter\n",
    "    X_tile = mask * X\n",
    "    Y = tf.nn.sigmoid(tf.matmul(X_tile, W) + b)\n",
    "    Z = tf.nn.sigmoid(tf.matmul(Y, W_prime) + b_prime)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", [None, n_visible], name=\"X_input\")\n",
    "mask = tf.placeholder(\"float32\", [None, n_visible], name=\"mask\")\n",
    "W_init_peak = 4 * np.sqrt(6. / (n_visible + n_hidden))\n",
    "W_init = tf.random_uniform(shape=[n_visible, n_hidden], minval=-W_init_peak, maxval=W_init_peak)\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "b = tf.Variable(tf.zeros([n_hidden]), name=\"b\")\n",
    "\n",
    "W_prime = tf.transpose(W, name=\"W_prime\")\n",
    "b_prime = tf.Variable(tf.zeros([n_visible], name=\"b_prime\"))\n",
    "\n",
    "Z = model(X, mask, W, b, W_prime, b_prime)\n",
    "\n",
    "# MSE\n",
    "cost = tf.reduce_sum(tf.pow(X - Z, 2))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.02).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 57565630000.0\n",
      "1 57565626000.0\n",
      "2 57565620000.0\n",
      "3 57565620000.0\n",
      "4 57565620000.0\n",
      "5 57565614000.0\n",
      "6 57565630000.0\n",
      "7 57565635000.0\n",
      "8 57565626000.0\n",
      "9 57565667000.0\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(10):\n",
    "        for start, end in zip(range(0, len(X_train), 128), range(128, len(X_train), 128)):\n",
    "            input_ = X_train[start:end]\n",
    "            mask_np = np.random.binomial(1, 1 - corruption_level, input_.shape)\n",
    "            sess.run(train_op, feed_dict={X: input_, mask: mask_np})\n",
    "\n",
    "        mask_np = np.random.binomial(1, 1 - corruption_level, X_test.shape)\n",
    "        print(i, sess.run(cost, feed_dict={X: X_test, mask: mask_np}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
